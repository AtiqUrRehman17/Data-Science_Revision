{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Pipeline in Machine Learning**\n",
    "\n",
    "In machine learning, a pipeline is a sequence of data processing steps that are chained together to automate and streamline the machine learning workflow. A pipeline allows you to combine multiple data preprocessing and model training steps into a single object, making it easier to organize and manage your machine learning code.\n",
    "\n",
    "> **Here are the key components of a pipeline:**\n",
    "\n",
    "**`Data Preprocessing Steps:`**\n",
    "Pipelines typically start with data preprocessing steps, such as feature scaling, feature encoding, handling missing values, or dimensionality reduction. These steps ensure that the data is in the appropriate format and quality for model training.\n",
    "\n",
    "**`Model Training:`**\n",
    "After the data preprocessing steps, the pipeline includes the training of a machine learning model. This can be a classifier for classification tasks, a regressor for regression tasks, or any other type of model depending on the problem at hand.\n",
    "\n",
    "**`Model Evaluation:`**\n",
    "Once the model is trained, the pipeline often incorporates steps for evaluating its performance. This may involve metrics calculation, cross-validation, or any other evaluation technique to assess the model's effectiveness.\n",
    "\n",
    "**`Predictions:`**\n",
    "After the model has been evaluated, the pipeline allows you to make predictions on new, unseen data using the trained model. This step applies the same preprocessing steps used during training to the new data before generating predictions.\n",
    "\n",
    "\n",
    "> **The main advantages of using pipelines in machine learning are:**\n",
    "\n",
    "**`Simplified Workflow:`** Pipelines provide a clean and organized structure for defining and managing the sequence of steps involved in machine learning tasks. This makes it easier to understand, modify, and reproduce the workflow.\n",
    "\n",
    "**`Avoiding Data Leakage:`** Pipelines ensure that data preprocessing steps are applied consistently to both the training and testing data, preventing data leakage that could lead to biased or incorrect results.\n",
    "\n",
    "**`Streamlined Model Deployment:`** Pipelines allow you to encapsulate the entire workflow, including data preprocessing and model training, into a single object. This simplifies the deployment of your machine learning model, as the same pipeline can be applied to new data without the need to reapply each individual step.\n",
    "\n",
    "**`Hyperparameter Tuning:`** Pipelines can be combined with techniques like grid search or randomized search for hyperparameter tuning. This allows you to efficiently explore different combinations of hyperparameters for your models.\n",
    "\n",
    "----\n",
    "**Summary:**\n",
    "\n",
    "\n",
    "Overall, pipelines are a powerful tool for managing and automating the machine learning workflow, promoting code reusability, consistency, and efficiency. They help streamline the development and deployment of machine learning models, making it easier to iterate and experiment with different approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is : 0.7988826815642458\n"
     ]
    }
   ],
   "source": [
    "# importing the libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import LabelEncoder,OneHotEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# load the dataset\n",
    "df = sns.load_dataset('titanic')\n",
    "\n",
    "# splittint the data into X and y\n",
    "X = df[['pclass', 'sex', 'age', 'fare', 'embarked']]\n",
    "y = df['survived']\n",
    "\n",
    "# USe train test spilt]\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2,random_state=42)\n",
    "\n",
    "# defien the column transformer for imputing the missing valies\n",
    "numaric_col = ['age','fare']\n",
    "cat_col = ['sex','pclass','embarked']\n",
    "\n",
    "\n",
    "# transforming the numaric col\n",
    "numaric_transform = Pipeline(steps=[\n",
    "    ('imputer',SimpleImputer(strategy='median'))\n",
    "])\n",
    "\n",
    "# transforming the cat col\n",
    "cat_transfrom = Pipeline(steps=[\n",
    "    ('imputer',SimpleImputer(strategy='most_frequent')),\n",
    "    ('encoder',OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "# creating preprocessor\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num',numaric_transform,numaric_col),\n",
    "        ('cat', cat_transfrom,cat_col)\n",
    "    ])\n",
    "\n",
    "# create a pipline with processor and random forest classifeir\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('preprocessor',preprocessor),\n",
    "    ('classifier',RandomForestClassifier(random_state=42))\n",
    "])\n",
    "# fit the pipline on Xtrain and y_train\n",
    "pipeline.fit(X_train,y_train)\n",
    "# predict throgh pipline\n",
    "y_pred = pipeline.predict(X_test)\n",
    "# accurcay score \n",
    "accuracy = accuracy_score(y_test,y_pred)\n",
    "print('accuracy is :',accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
