{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Decision Tree Algorithem**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example of Entropy Gini Impurity and Information Gain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the math library\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example dataset\n",
    "# we have to class ,Class A and Class B\n",
    "# lets say we have a dataset of elemments 10 in which 4 elements of class A and 6 elements of class B\n",
    "n_A = 4 \n",
    "n_B = 6 \n",
    "total = n_A + n_B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets calculate thier propotion\n",
    "prop_A = n_A/total\n",
    "prop_B = n_B/total\n",
    "# u can also print it\n",
    "print('Propotion of A :',prop_A)\n",
    "print('Propotion of b :',prop_B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets calculate entropy\n",
    "# entropy is the measure of uncertanity\n",
    "entropy = -prop_A * math.log2(prop_A) - prop_B * math.log2(prop_B)\n",
    "entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gini impurity\n",
    "gini = 1 - prop_A**2 - prop_B**2\n",
    "print('Gini impurity :',gini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# information gain\n",
    "# assuming a split on some feature divides the dataset into two subsetss\n",
    "# sub : 1 2 elements in A and 3 elements in B\n",
    "# sub 2 : 2 elements in A and 3 elements in B\n",
    "# entropy and size for each subset\n",
    "n_1_A,n_1_B = 2,3\n",
    "n_2_A,n_2_B = 2,3\n",
    "p_1_A = n_1_A/ (n_1_A + n_1_B)\n",
    "p_1_B = n_1_B / (n_1_A + n_1_B)\n",
    "#  now To calculate the entropy of first split\n",
    "entropy_1 = -p_1_A * math.log2(p_1_A) - p_1_B * math.log2(p_1_B) if p_1_A and p_1_B else 0\n",
    "# now taking the propation of the 2nd split \n",
    "p_2_A = n_2_A / (n_2_A + n_2_B)\n",
    "p_2_B = n_2_B / (n_2_A + n_2_B)\n",
    "# now taking the 2nd split entorpy\n",
    "entropy_2 = - p_2_A * math.log2(p_2_A) - p_2_B * math.log2(p_2_A) if p_2_A and p_2_B else 0\n",
    "# info gain\n",
    "info_gain = entropy - ((n_1_A + n_1_B)/ total * entropy_1 + (n_2_A + n_2_B) / total * entropy_2) \n",
    "print('info gain :',info_gain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------\n",
    "# **_Decision Tree Classifier_**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importing the lobraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score,confusion_matrix,classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data\n",
    "df = sns.load_dataset('titanic')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the missing values\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# here we know that there are missin values in the data so we need to preprocces the data\n",
    "# 1 : lets drop the deck co;umn\n",
    "df.drop('deck',axis=1,inplace=True)\n",
    "# imputing the missing values in age and fare using the simple imputer\n",
    "imputer = SimpleImputer(strategy='median')\n",
    "df[['age','fare']] = imputer.fit_transform(df[['age','fare']])\n",
    "# now to imputer the missing values of the embark and embarked_twon using simple imputer mode\n",
    "imputer = SimpleImputer(strategy='most_frequent')\n",
    "df[['embarked','embark_town']] = imputer.fit_transform(df[['embarked','embark_town']])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the missing values agin\n",
    "df.isnull().sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoding the data where the type is categorical or object using for loop\n",
    "le = LabelEncoder()\n",
    "for col in df.select_dtypes(include=['category','object']):\n",
    "    df[col] = le.fit_transform(df[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now checking the data\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## here u can see the data is encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the data into X and y\n",
    "X = df.drop('survived',axis=1)\n",
    "y = df['survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now train test split\n",
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# call the model \n",
    "model = DecisionTreeClassifier(criterion='entropy',max_depth=3,random_state=42)\n",
    "# fit the model in train test data\n",
    "model.fit(X_train,y_train)\n",
    "# now prediction of the X_test\n",
    "y_pred = model.predict(X_test)\n",
    "# evluating the model\n",
    "print(confusion_matrix(y_test,y_pred))\n",
    "print(classification_report(y_test,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the tree in dot file\n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_graphviz(model,out_file='./saved_models/decision_tree_01.dot',feature_names=X.columns,filled=True,rounded=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
